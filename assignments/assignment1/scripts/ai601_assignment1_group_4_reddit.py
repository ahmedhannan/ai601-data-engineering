# -*- coding: utf-8 -*-
"""AI601_Assignment1_Group-4_Reddit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SOFQrpmFXposOBNlDs2RTLF7K1sUyCi0

# Part 1: Reddit Data Collection
"""

!pip install praw pytrends

# %% [code]
import praw
import csv
import pandas as pd
import time
from pytrends.request import TrendReq

# ---------------------------
# Part 1: Reddit Data Collection
# ---------------------------

reddit = praw.Reddit(
    client_id='vnHAZ7gjpqDp_BwAkyg6OA',
    client_secret='AIkXco5-yWdTMwIZi0PfqOwCofCqIQ',
    user_agent= 'TeslaEV by u/ComprehensiveMix216',
    password="",
    username="",

)

try:
    print("Logged in as:", reddit.user.me())
except Exception as e:
    print("Error:", e)

print(reddit.user.me())

# We'll collect about 100-200 posts/comments that match our keywords.
reddit_data = []
subreddits = ['ElectricVehicles', 'TeslaMotors']
keywords = ["electric vehicle", "tesla", "ev charging"]

# Loop through each subreddit and keyword
for subreddit in subreddits:
    for keyword in keywords:
        subreddit_instance = reddit.subreddit(subreddit)
        # Search for posts matching the keyword
        for submission in subreddit_instance.search(keyword, limit=50):
            post = {
                'title': submission.title,
                'post_text': submission.selftext,
                'author': str(submission.author),
                'date': time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(submission.created_utc)),
                'upvotes': submission.score,
                'subreddit': submission.subreddit.display_name
            }
            reddit_data.append(post)
            # Break out when we have collected enough posts (~200)
            if len(reddit_data) >= 200:
                break
        if len(reddit_data) >= 200:
            break
    if len(reddit_data) >= 200:
        break

# Write the collected Reddit data to a CSV file.
reddit_csv_filename = 'reddit_ev_data.csv'
with open(reddit_csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
    fieldnames = ['title', 'post_text', 'author', 'date', 'upvotes', 'subreddit']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    for post in reddit_data:
        writer.writerow(post)

print(f"Collected {len(reddit_data)} Reddit posts and saved to {reddit_csv_filename}.")